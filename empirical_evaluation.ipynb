{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "from src.visualizations import * \n",
    "from src.statistical_tests import *\n",
    "from src.fairness import kl, cheb, tv, chi \n",
    "from src.fairness import compute_RDP, compute_PR, compute_UCPR \n",
    "from src.evaluation import compute_losses, compute_diversity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading all Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METHODS = [\"pulse\", \"psp\", \"fairpsp\", \"posteriorSampling\",  \"ddrm\"] \n",
    "RACES = [\"White\", \n",
    "       \"Indian\", \n",
    "       \"Black\", \n",
    "       \"Latino_Hispanic\",\n",
    "       \"Southeast Asian\",\n",
    "       \"East Asian\",\n",
    "       \"Middle Eastern\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = {\"fairface\": {method: f\"upsampled_imgs/fairface/16_to_128/{method}/\" for method in METHODS}, \n",
    "             \"fairface_avg\": {method: f\"upsampled_imgs/fairface/4_to_128/{method}/\" for method in METHODS},\n",
    "             \"fairface_noisy_avg\": {method: f\"upsampled_imgs/fairface/4noise_to_128/{method}/\" for method in METHODS},\n",
    "             \"unfairface\": {method: f\"upsampled_imgs/unfairface/16_to_128/{method}/\" for method in METHODS},\n",
    "             \"unfairface_avg\": {method: f\"upsampled_imgs/unfairface/4_to_128/{method}/\" for method in METHODS},\n",
    "              \"unfairface_noisy_avg\": {method: f\"upsampled_imgs/unfairface/4noise_to_128/{method}/\" for method in METHODS},\n",
    "             }\n",
    "\n",
    "labels_path = \"data/fairface/fairface_label_val.csv\"\n",
    "real_img_path = \"data/fairface/test_correct_prediction/\"\n",
    "img_paths[\"fairface\"][\"real\"] = real_img_path \n",
    "img_paths[\"unfairface\"][\"real\"] = real_img_path \n",
    "avg_img_path = \"data/fairface/avg_faces/\"\n",
    "img_paths[\"fairface_avg\"][\"real\"] = avg_img_path\n",
    "img_paths[\"unfairface_avg\"][\"real\"] = avg_img_path \n",
    "noisy_avg_img_path = \"data/fairface/avg_noisy_faces/\"\n",
    "img_paths[\"fairface_noisy_avg\"][\"real\"] = noisy_avg_img_path\n",
    "img_paths[\"unfairface_noisy_avg\"][\"real\"] = noisy_avg_img_path \n",
    "\n",
    "# lr images are computed on the fly \n",
    "img_paths[\"fairface\"][\"lr\"] = \"\"\n",
    "img_paths[\"unfairface\"][\"lr\"] = \"\"\n",
    "img_paths[\"fairface_avg\"][\"lr\"] = \"\"\n",
    "img_paths[\"unfairface_avg\"][\"lr\"] = \"\"\n",
    "img_paths[\"fairface_noisy_avg\"][\"lr\"] = \"\"\n",
    "img_paths[\"unfairface_noisy_avg\"][\"lr\"] = \"\"\n",
    "\n",
    "# reorder the paths such that the keys()-order is Original - LR - PULSE - etc \n",
    "# Swap the last two keys to the front\n",
    "keys = [\"real\", \"lr\"] + METHODS\n",
    "for dataset_name in img_paths.keys():\n",
    "    img_paths[dataset_name] = OrderedDict((key, img_paths[dataset_name][key]) for key in keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Qualitative Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"plots/reconstructions\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Visualize Random Reconstructions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfairface: \n",
    "visualize_reconstructions(img_paths[\"unfairface\"], num_imgs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairface: \n",
    "visualize_reconstructions(img_paths[\"fairface\"], num_imgs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UnfairFace vs FairFace \n",
    "visualize_reconstructions_comparison(img_paths[\"unfairface\"], img_paths[\"fairface\"], num_imgs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teaser Image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names_teaser = [\"22.jpg\", \"106.jpg\", \"118.jpg\", \"511.jpg\"]\n",
    "visualize_reconstructions(img_paths[\"unfairface\"], img_names=img_names_teaser)\n",
    "plt.savefig(\"plots/reconstructions/teaser_unfairface.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names_teaser = [\"22.jpg\", \"106.jpg\", \"118.jpg\", \"511.jpg\"]\n",
    "visualize_reconstructions(img_paths[\"fairface\"], img_names=img_names_teaser)\n",
    "plt.savefig(\"plots/reconstructions/teaser_fairface.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Visualize Samples from a specific Ethnicity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(labels_path)\n",
    "\n",
    "def return_img_names_in_test_set(test_set_dir, race=\"White\", num_imgs=8):\n",
    "    \"\"\"Reads the labels file and returns the image names of a specific race.\"\"\"\n",
    "    img_names = list(labels_df[\"file\"][labels_df[\"race\"]==race])\n",
    "    filenames_test = os.listdir(test_set_dir)\n",
    "    img_names_return = []\n",
    "    index = 0\n",
    "    while len(img_names_return) < num_imgs:\n",
    "        img_name = img_names[index].split(\"/\")[-1]\n",
    "        if img_name in filenames_test:\n",
    "            img_names_return.append(img_name)\n",
    "        index += 1 \n",
    "    return img_names_return \n",
    "\n",
    "img_names_black = return_img_names_in_test_set(img_paths[\"fairface\"][\"real\"], \"Black\", num_imgs=12)\n",
    "img_names_white = return_img_names_in_test_set(img_paths[\"fairface\"][\"real\"], \"White\", num_imgs=4)\n",
    "img_names_indian = return_img_names_in_test_set(img_paths[\"fairface\"][\"real\"], \"Indian\", num_imgs=12)\n",
    "img_names_me = return_img_names_in_test_set(img_paths[\"fairface\"][\"real\"], \"Middle Eastern\", num_imgs=12)\n",
    "img_names_ea = return_img_names_in_test_set(img_paths[\"fairface\"][\"real\"], \"East Asian\", num_imgs=12)\n",
    "img_names_sea = return_img_names_in_test_set(img_paths[\"fairface\"][\"real\"], \"Southeast Asian\", num_imgs=12)\n",
    "img_names_lh = return_img_names_in_test_set(img_paths[\"fairface\"][\"real\"], \"Latino_Hispanic\", num_imgs=12)\n",
    "\n",
    "# cherry-picked images\n",
    "img_names_black_selected = [img_names_black[j] for j in [2, 7, 8]]\n",
    "img_names_indian_selected = [img_names_indian[j] for j in [1, 4, 8]] \n",
    "img_names_me_selected = [img_names_me[j] for j in [0, 6, 11]]\n",
    "img_names_ea_selected = [img_names_ea[j] for j in [0, 6, 9]] \n",
    "img_names_sea_selected = [img_names_sea[j] for j in [1, 4, 10]] \n",
    "img_names_lh_selected = [img_names_lh[j] for j in [1, 4, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions(img_paths[\"unfairface\"], img_names=img_names_white)\n",
    "plt.savefig(\"plots/reconstructions/white_unfairface.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions(img_paths[\"fairface\"], img_names=img_names_white)\n",
    "plt.savefig(\"plots/reconstructions/white_fairface.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions_comparison(img_paths[\"unfairface\"], img_paths[\"fairface\"], img_names=img_names_white )\n",
    "plt.savefig(\"plots/reconstructions/comparison_white.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions(img_paths[\"unfairface\"], img_names=img_names_black_selected)\n",
    "plt.savefig(\"plots/reconstructions/black_unfairface.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions(img_paths[\"fairface\"], img_names=img_names_black_selected)\n",
    "plt.savefig(\"plots/reconstructions/black_fairface.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions_comparison(img_paths[\"unfairface\"], img_paths[\"fairface\"], img_names=img_names_black_selected)\n",
    "plt.savefig(\"plots/reconstructions/comparison_black.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot More Headscarves, Bindis, and Monolid Eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names_bindis = [f\"{nr}.jpg\" for nr in [136, 900, 1637]] \n",
    "visualize_reconstructions(img_paths[\"unfairface\"], img_names=img_names_bindis)\n",
    "plt.savefig(\"plots/reconstructions/bindis_unfairface.pdf\")\n",
    "\n",
    "visualize_reconstructions(img_paths[\"fairface\"], img_names=img_names_bindis)\n",
    "plt.savefig(\"plots/reconstructions/bindis_fairface.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names_scarves = [f\"{nr}.jpg\" for nr in [1214, 1404, 1901]] \n",
    "visualize_reconstructions(img_paths[\"unfairface\"], img_names=img_names_scarves)\n",
    "plt.savefig(\"plots/reconstructions/scarves_unfairface.pdf\")\n",
    "\n",
    "visualize_reconstructions(img_paths[\"fairface\"], img_names=img_names_scarves)\n",
    "plt.savefig(\"plots/reconstructions/scarves_fairface.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names_monolid = [f\"{nr}.jpg\" for nr in [138, 346, 399]] \n",
    "visualize_reconstructions(img_paths[\"unfairface\"], img_names=img_names_monolid)\n",
    "plt.savefig(\"plots/reconstructions/monolid_unfairface.pdf\")\n",
    "\n",
    "visualize_reconstructions(img_paths[\"fairface\"], img_names=img_names_monolid)\n",
    "plt.savefig(\"plots/reconstructions/monolid_fairface.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining Races:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_race2img = {\"Indian\": img_names_indian_selected, \n",
    "                \"Southeast Asian\": img_names_sea_selected,\n",
    "                \"East Asian\": img_names_ea_selected,\n",
    "                \"Middle Eastern\": img_names_me_selected,\n",
    "                \"Latino_Hispanic\": img_names_lh_selected}\n",
    "\n",
    "for race in [\"Indian\", \"Southeast Asian\", \"East Asian\", \"Middle Eastern\", \"Latino_Hispanic\"]:\n",
    "    img_names = dict_race2img[race]\n",
    "    visualize_reconstructions(img_paths[\"fairface\"], img_names=img_names)\n",
    "    plt.savefig(f\"plots/reconstructions/{race}_fairface.pdf\")\n",
    "    visualize_reconstructions(img_paths[\"unfairface\"], img_names=img_names)\n",
    "    plt.savefig(f\"plots/reconstructions/{race}_unfairface.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Visualize multiple Samples given LowRes Downsampled to 4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions_avg(img_paths[\"unfairface_avg\"], race=\"White\", num_imgs=3)\n",
    "plt.savefig(\"plots/reconstructions/white_unfairface_avg.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions_avg(img_paths[\"fairface_avg\"], race=\"White\", num_imgs=3)\n",
    "plt.savefig(\"plots/reconstructions/white_fairface_avg.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions_avg_comparison(img_paths[\"unfairface_avg\"], img_paths[\"fairface_avg\"], race=\"White\", num_imgs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions_avg(img_paths[\"unfairface_avg\"], race=\"Black\", num_imgs=3)\n",
    "plt.savefig(\"plots/reconstructions/black_unfairface_avg.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions_avg(img_paths[\"fairface_avg\"], race=\"Black\", num_imgs=3)\n",
    "plt.savefig(\"plots/reconstructions/black_fairface_avg.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions_avg_comparison(img_paths[\"unfairface_avg\"], img_paths[\"fairface_avg\"], race=\"Black\", num_imgs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy Averages as Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_avg = img_paths[\"unfairface_avg\"][\"real\"]\n",
    "print(path_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions_noisy_avg(img_paths[\"unfairface_noisy_avg\"], path_avg=path_avg, race=\"White\", num_imgs=3)\n",
    "plt.savefig(\"plots/reconstructions/white_unfairface_noisy_avg.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions_noisy_avg(img_paths[\"fairface_noisy_avg\"], path_avg=path_avg, race=\"White\", num_imgs=3)\n",
    "plt.savefig(\"plots/reconstructions/white_fairface_noisy_avg.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions_noisy_avg(img_paths[\"unfairface_noisy_avg\"], path_avg=path_avg, race=\"Black\", num_imgs=3)\n",
    "plt.savefig(\"plots/reconstructions/black_unfairface_noisy_avg.pdf\")\n",
    "visualize_reconstructions_noisy_avg(img_paths[\"fairface_noisy_avg\"], path_avg=path_avg, race=\"Black\", num_imgs=3)\n",
    "plt.savefig(\"plots/reconstructions/black_fairface_noisy_avg.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Quantitative Results\n",
    "## 3.1. Calculate all Losses and obtain Losses-DFs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losses_to_dfs(setting):\n",
    "    \"\"\"Returns a dict of loss dfs. Each df contains the losses for a specific method.\"\"\"\n",
    "    assert setting in [\"fairface\", \"unfairface\"]\n",
    "    losses_dir = os.path.join(\"evaluation\", setting) \n",
    "    os.makedirs(losses_dir, exist_ok=True)\n",
    "    dfs = {}\n",
    "    for method in METHODS: \n",
    "        losses_path = os.path.join(losses_dir, f\"losses_{method}.csv\")\n",
    "        if os.path.exists(losses_path):\n",
    "            dfs[method] = pd.read_csv(losses_path)\n",
    "        else:\n",
    "            df = compute_losses(img_paths[setting][\"real\"], img_paths[setting][method], labels_path=labels_path)\n",
    "            dfs[method] = df\n",
    "            df.to_csv(losses_path, index=True)\n",
    "    return dfs \n",
    "      \n",
    "dfs = {}      \n",
    "for setting in [\"fairface\", \"unfairface\"]:\n",
    "    dfs[setting] = losses_to_dfs(setting)\n",
    "    \n",
    "print(dfs[\"fairface\"][\"pulse\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSSES = [\"lpips\", \n",
    "          \"ssim\",\n",
    "          \"race_cos\", \n",
    "          \"race_0-1\", \n",
    "          \"niqe16\", \n",
    "          \"blur\"\n",
    "          ]\n",
    "\n",
    "def evaluate_performance(dfs, setting):\n",
    "    performances = []\n",
    "    for method in METHODS:\n",
    "        performance = {\"method\": method}\n",
    "        for loss in LOSSES:\n",
    "            if loss == \"race_0-1\":\n",
    "                performance[loss] = 1 - np.mean(dfs[setting][method][loss])\n",
    "            else:\n",
    "                performance[loss] = np.mean(dfs[setting][method][loss])\n",
    "        performances.append(performance)\n",
    "    losses_df = pd.concat([pd.DataFrame([performance]) for performance in performances], ignore_index=True)\n",
    "    losses_df[\"blur\"] = losses_df[\"blur\"] * 100 \n",
    "    return losses_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_unfairface = evaluate_performance(dfs, \"unfairface\")\n",
    "losses_unfairface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_fairface = evaluate_performance(dfs, \"fairface\")\n",
    "losses_fairface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine them into one DataFrame \n",
    "# (See Table 1 in the Paper)\n",
    "losses_both = pd.DataFrame()\n",
    "losses_both[\"method\"] = [name_to_str(method) for method in losses_unfairface[\"method\"]]\n",
    "for label in losses_unfairface.columns:\n",
    "    if label == \"method\":\n",
    "        continue \n",
    "    losses_both[label] = losses_unfairface[label]\n",
    "    losses_both[f\"{label}-F\"] = losses_fairface[label]\n",
    "print(losses_both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2. Test whether the values are statistically different FairFace vs UnFairFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Wilcoxon Test (less Assumptions; nonparametric version of paired T-Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_sample_wilcoxon(dfs, alpha=0.05, methods=METHODS, losses=LOSSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = two_sample_wilcoxon(dfs, alpha=0.05, return_decision=False, methods=METHODS, losses=LOSSES)\n",
    "p_values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that we cannot run a paired t-Test because Normality of the features is violated in all cases but the NIQE-Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paired_t_test_assumption(dfs, methods=METHODS, losses=LOSSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = two_sample_paired_ttest(dfs, alpha=0.05, return_decision=False, methods=METHODS, losses=LOSSES)\n",
    "# The test only applies for NIQE because we cannot assume the other scores to be normally distributed! \n",
    "p_values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pearson's Chi-squared test for race_0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_sample_chi2(dfs, 0.05, methods=METHODS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Evaluating Fairness\n",
    "### 3.3.1 Plotting Performance per Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loss in LOSSES:\n",
    "    if loss==\"race_cos\":\n",
    "        ylim = [0, 0.4]\n",
    "    elif loss==\"race_0-1\":\n",
    "        ylim = [0, 1]\n",
    "    else:\n",
    "        ylim = None \n",
    "    plot_performance_per_race(loss, dfs, \"fairface\", methods=METHODS, ylim=ylim)\n",
    "    plot_performance_per_race(loss, dfs, \"unfairface\", methods=METHODS, ylim=ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling the above (for the race prediction accuracy) provides a visualization of RDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rdp(dfs, \"unfairface\", methods=METHODS, ylim=[0,0.5])\n",
    "plot_rdp(dfs, \"fairface\", methods=METHODS, ylim=[0,0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Plotting the Proportional Representation Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr(dfs, \"unfairface\", methods=METHODS, ylim=[0,0.6])\n",
    "plot_pr(dfs, \"fairface\", methods=METHODS, ylim=[0, 0.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. Evaluating Fairness according to the introduced Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdps = compute_RDP(dfs, \"fairface\", methods=METHODS, races=RACES)\n",
    "prs = compute_PR(dfs, \"fairface\", methods=METHODS, races=RACES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation \n",
    "divergences = {\"KL\": kl, \"Cheb\": cheb, \"TV\": tv, \"chi\": chi}\n",
    "\n",
    "divergences = {\"chi\": chi, \"Cheb\": cheb}\n",
    "\n",
    "def evaluating_fairness(dfs, setting):\n",
    "    list_fairness = [] \n",
    "    rdps = compute_RDP(dfs, setting, methods=METHODS, races=RACES)\n",
    "    prs = compute_PR(dfs, setting, methods=METHODS, races=RACES)\n",
    "    for method in METHODS:\n",
    "        fairness = {\"method\": name_to_str(method)}\n",
    "        rdp = rdps[method]\n",
    "        pr = prs[method]\n",
    "        for div_name in divergences.keys():\n",
    "            fairness[f\"RDP-{div_name}\"] = divergences[div_name](rdp)\n",
    "        for div_name in divergences.keys():\n",
    "            fairness[f\"PR-{div_name}\"] = divergences[div_name](pr)\n",
    "        list_fairness.append(fairness)\n",
    "    fairness_df = pd.concat([pd.DataFrame([fairness]) for fairness in list_fairness], ignore_index=True)\n",
    "    return fairness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_unfairface = evaluating_fairness(dfs, \"unfairface\")\n",
    "fairness_unfairface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_fairface = evaluating_fairness(dfs, \"fairface\")\n",
    "fairness_fairface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine them into one DataFrame \n",
    "fairness_both = pd.DataFrame()\n",
    "fairness_both[\"method\"] = fairness_unfairface[\"method\"]\n",
    "for label in fairness_unfairface.columns:\n",
    "    if label == \"method\":\n",
    "        continue \n",
    "    fairness_both[label] = fairness_unfairface[label]\n",
    "    fairness_both[f\"{label}-F\"] = fairness_fairface[label]\n",
    "print(fairness_both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.1 Statistically Testing Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_fairness(dfs, \"unfairface\", methods=METHODS, races=RACES, metric=\"rdp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_fairness(dfs, \"fairface\", methods=METHODS, races=RACES, metric=\"rdp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_fairness(dfs, \"unfairface\", methods=METHODS, races=RACES, metric=\"pr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_fairness(dfs, \"fairface\", methods=METHODS, races=RACES, metric=\"pr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluating Diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Generate Diversity DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_to_dfs(setting):\n",
    "    assert setting in [\"fairface_avg\", \"unfairface_avg\", \"fairface_noisy_avg\", \"unfairface_noisy_avg\"]\n",
    "    losses_dir = os.path.join(\"evaluation\", setting) \n",
    "    os.makedirs(losses_dir, exist_ok=True)\n",
    "    dfs = {}\n",
    "    for method in METHODS: \n",
    "        losses_path = os.path.join(losses_dir, f\"losses_{method}.csv\")\n",
    "        if os.path.exists(losses_path):\n",
    "            dfs[method] = pd.read_csv(losses_path)\n",
    "        else:\n",
    "            if setting in [\"fairface_avg\", \"unfairface_avg\"]:\n",
    "                num_duplicates = 100 \n",
    "            elif setting in [\"fairface_noisy_avg\", \"unfairface_noisy_avg\"]:\n",
    "                num_duplicates = 1 \n",
    "            df = compute_diversity(img_paths[setting][\"real\"], \n",
    "                                   img_paths[setting][method], \n",
    "                                   labels_path=labels_path, \n",
    "                                   num_duplicates=num_duplicates)\n",
    "            dfs[method] = df\n",
    "            df.to_csv(losses_path, index=True)\n",
    "    return dfs \n",
    "      \n",
    "for setting in [\"fairface_avg\", \"unfairface_avg\", \"fairface_noisy_avg\", \"unfairface_noisy_avg\"]:\n",
    "    dfs[setting] = diversity_to_dfs(setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ucpr(dfs, \"unfairface_avg\", methods=METHODS, races=RACES, ylim=[0, 1.])\n",
    "plot_ucpr(dfs, \"fairface_avg\", methods=METHODS, races=RACES, ylim=[0, 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation \n",
    "divergences = {\"KL\": kl, \"Cheb\": cheb, \"TV\": tv, \"chi\": chi}\n",
    "divergences = {\"chi\": chi, \"Cheb\": cheb}\n",
    "\n",
    "def evaluating_diversity(dfs, setting):\n",
    "    list_diversity = [] \n",
    "    ucprs = compute_UCPR(dfs, setting, methods=METHODS, races=RACES)\n",
    "    for method in METHODS:\n",
    "        diversity = {\"method\": name_to_str(method)}\n",
    "        ucpr = ucprs[method]\n",
    "        for div_name in divergences.keys():\n",
    "            diversity[f\"UCPR-{div_name}\"] = divergences[div_name](ucpr)\n",
    "        list_diversity.append(diversity)\n",
    "    diversity_df = pd.concat([pd.DataFrame([fairness]) for fairness in list_diversity], ignore_index=True)\n",
    "    return diversity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_unfairface = evaluating_diversity(dfs, \"unfairface_avg\")\n",
    "diversity_unfairface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_fairface = evaluating_diversity(dfs, \"fairface_avg\")\n",
    "diversity_fairface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine them into one DataFrame \n",
    "diversity_both = pd.DataFrame()\n",
    "diversity_both[\"method\"] = diversity_unfairface[\"method\"]\n",
    "for label in diversity_unfairface.columns:\n",
    "    if label == \"method\":\n",
    "        continue \n",
    "    diversity_both[label] = diversity_unfairface[label]\n",
    "    diversity_both[f\"{label}-F\"] = diversity_fairface[label]\n",
    "print(diversity_both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Testing Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_fairness(dfs, \"unfairface_avg\", methods=METHODS, races=RACES, metric=\"ucpr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_fairness(dfs, \"fairface_avg\", methods=METHODS, races=RACES, metric=\"ucpr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Testing Diversity with Noisy Inputs\n",
    "Instead of reconstructing each image 100 times, we take one image, calculate 100 perturbed versions of it, and reconstruct these. The advantage is that it allows us to compute a diversity for pSp and fairpSp, whose reconstruction is deterministic. That is, every reconstruction of the same image is the same. This allows us to compute 100 different images even with pSp and fairpSp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ucpr(dfs, \"unfairface_noisy_avg\", methods=METHODS, races=RACES, ylim=[0, 1.])\n",
    "plot_ucpr(dfs, \"fairface_noisy_avg\", methods=METHODS, races=RACES, ylim=[0, 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_unfairface = evaluating_diversity(dfs, \"unfairface_noisy_avg\")\n",
    "diversity_fairface = evaluating_diversity(dfs, \"fairface_noisy_avg\")\n",
    "\n",
    "# Combine them into one DataFrame \n",
    "diversity_both = pd.DataFrame()\n",
    "diversity_both[\"method\"] = diversity_unfairface[\"method\"]\n",
    "for label in diversity_unfairface.columns:\n",
    "    if label == \"method\":\n",
    "        continue \n",
    "    diversity_both[label] = diversity_unfairface[label]\n",
    "    diversity_both[f\"{label}-F\"] = diversity_fairface[label]\n",
    "print(diversity_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_fairness(dfs, \"unfairface_noisy_avg\", methods=METHODS, races=RACES, metric=\"ucpr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_fairness(dfs, \"fairface_noisy_avg\", methods=METHODS, races=RACES, metric=\"ucpr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
